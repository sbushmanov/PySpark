{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Table of Contents</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:01:00.811911Z",
     "start_time": "2021-12-06T18:00:57.710176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'test'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.host', '192.168.199.77'),\n",
       " ('spark.driver.port', '10881'),\n",
       " ('spark.hadoop.fs.default.name', 'hdfs://localhost:9000'),\n",
       " ('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.startTime', '1638813659254'),\n",
       " ('spark.hadoop.fs.defaultFS', 'hdfs://localhost:9000'),\n",
       " ('spark.app.id', 'local-1638813659923'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.\n",
    "    appName(\"test\").\n",
    "    enableHiveSupport().\n",
    "    config(\"spark.sql.warehouse.dir\",\"/user/hive/warehouse\").\n",
    "    getOrCreate()\n",
    ")\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:01:46.257021Z",
     "start_time": "2021-12-06T18:01:45.816680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|station_id|                name|      lat|       long|dockcount|landmark|installation|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|         2|San Jose Diridon ...|37.329732|-121.901782|       27|San Jose|    8/6/2013|\n",
      "|         3|San Jose Civic Ce...|37.330698|-121.888979|       15|San Jose|    8/5/2013|\n",
      "|         4|Santa Clara at Al...|37.333988|-121.894902|       11|San Jose|    8/6/2013|\n",
      "|         5|    Adobe on Almaden|37.331415|  -121.8932|       19|San Jose|    8/5/2013|\n",
      "|         6|    San Pedro Square|37.336721|-121.894074|       15|San Jose|    8/7/2013|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"file:///home/sergey/Py_SparkDataFrame_edx_CS105_CS110_CS120/data/201408_station_data.csv\"\n",
    "df = spark.read.csv(path, header=True, inferSchema = True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:02:18.355378Z",
     "start_time": "2021-12-06T18:02:18.350806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- dockcount: integer (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:02:21.385339Z",
     "start_time": "2021-12-06T18:02:21.096905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:02:29.854250Z",
     "start_time": "2021-12-06T18:02:29.843020Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType, DateType\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:03:27.480146Z",
     "start_time": "2021-12-06T18:03:27.473674Z"
    }
   },
   "outputs": [],
   "source": [
    "to_int = F.udf(lambda x: int(x), IntegerType())\n",
    "to_float = F.udf(lambda x: float(x), DoubleType())\n",
    "to_date = F.udf(lambda x: dt.strptime(x, '%m/%d/%Y'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:03:31.469875Z",
     "start_time": "2021-12-06T18:03:31.385637Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (df.select(to_int(df['station_id']).alias('station_id')\n",
    "              ,df['name']\n",
    "              ,to_float(df['lat']).alias('lat')\n",
    "              ,to_float(df['long']).alias('long')\n",
    "              ,to_int(df['dockcount']).alias('dockcount')\n",
    "              ,df['landmark']\n",
    "              ,to_date(df['installation']).alias('installation')\n",
    "              )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:03:34.023701Z",
     "start_time": "2021-12-06T18:03:33.884935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:03:49.146527Z",
     "start_time": "2021-12-06T18:03:48.466073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|station_id|                name|      lat|       long|dockcount|landmark|installation|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|         2|San Jose Diridon ...|37.329732|-121.901782|       27|San Jose|  2013-08-06|\n",
      "|         3|San Jose Civic Ce...|37.330698|-121.888979|       15|San Jose|  2013-08-05|\n",
      "|         4|Santa Clara at Al...|37.333988|-121.894902|       11|San Jose|  2013-08-06|\n",
      "|         5|    Adobe on Almaden|37.331415|  -121.8932|       19|San Jose|  2013-08-05|\n",
      "|         6|    San Pedro Square|37.336721|-121.894074|       15|San Jose|  2013-08-07|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:03:51.574243Z",
     "start_time": "2021-12-06T18:03:51.568276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- dockcount: integer (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:04:16.768866Z",
     "start_time": "2021-12-06T18:04:16.749146Z"
    }
   },
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView('station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:04:35.526770Z",
     "start_time": "2021-12-06T18:04:35.221549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-----------+---------+-------------+------------+\n",
      "|station_id|                name|      lat|       long|dockcount|     landmark|installation|\n",
      "+----------+--------------------+---------+-----------+---------+-------------+------------+\n",
      "|         2|San Jose Diridon ...|37.329732|-121.901782|       27|     San Jose|  2013-08-06|\n",
      "|        61|     2nd at Townsend|37.780526|-122.390288|       27|San Francisco|  2013-08-22|\n",
      "|        67|      Market at 10th|37.776619|-122.417385|       27|San Francisco|  2013-08-23|\n",
      "|        77|   Market at Sansome|37.789625|-122.400811|       27|San Francisco|  2013-08-25|\n",
      "+----------+--------------------+---------+-----------+---------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from station where dockcount == 27\").show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
